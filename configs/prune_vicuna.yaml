_base_: ["./_base_/c4.yaml"]

model:
    model_class: "AutoModelForCausalLM"
    model_name: "lmsys/vicuna-7b-v1.5"
    dtype: float
    tokenizer_class: "AutoTokenizer"
    tokenizer_name: "lmsys/vicuna-7b-v1.5"
    # Vicuna needs mem_efficient_sdp to be False
    mem_efficient_sdp: False

pruning_dir: "./workdirs/prune_vicuna/"

pruner:
    type: ForwardPruner
    dual_insert_layer: model.embed_tokens
    use_loss: True
    criterion:
        scope: "global_thres"
        strategy: "backward_grads_activations"
        group: ["attn"]
        exclude_layers: ["embed_tokens", "norm", "lm_head", "down_proj", "o_proj", "mlp"]
    sparsities: [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]

test_cfg:
    # testing time sparsity can be a subset of pruning time sparsity
    sparsities: [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]
    use_prior: False
    print_table: False
    testing_manager:
        type: ForwardPrunerTestingManager
    evaluator:
        type: Perplexity
